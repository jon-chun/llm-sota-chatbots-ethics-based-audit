![Download](apq_paper_cover_20230108.png)

[Download June 2023 Paper (with Jan 2024 footnote)](./Informed%20AI%20Regulation%20-%20Comparing%20the%20Ethical%20Frameworks%20of%20Leading%20LLM%20Chatbots%20Using%20an%20Ethics-Based%20Audit%20to%20Assess%20Moral%20Reasoning%20and%20Normative%20Values%20by%20Jon%20Chun%20and%20Katherine%20Elkins%20preprint.pdf)

## Informed AI Regulation: Comparing the Ethical Frameworks of Leading LLM Chatbots Using an Ethics-Based Audit to Assess Moral Reasoning and Normative Values

### By Jon Chun and Katherine Elkins


## UPDATE: (8 Jan 2024)

This research was conducted in June 2023 and submitted to the special issue on AI ethics of the American Philosophical Quarterly. After a six-month wait for peer review, we received readersâ€™ reports. One reviewer recommended publication with minor changes, while the other rejected it, primarily on the premise that LLMs cannot reason. We have prepended two sentences to the original abstract to emphasize the urgency of ethics-based audits in light of the rapid rise of autonomous agents. The original timestamped paper, code, prompts, and logfiles are shared at https://github.com/jon-chun/llm-sota-chatbots-ethics-based-audit

## ABSTRACT

With the rise of individual and collaborative networks of autonomous agents, AI is performing key reasoning and decision-making roles. For this reason, ethics-based audits play a pivotal role in the rapidly growing fields of AI safety and regulation. This paper undertakes an ethics-based audit to probe the 8 leading commercial and open-source Large Language Models including GPT-4. We assess explicability and trustworthiness by a. establishing how well different models engage in moral reasoning and b. comparing normative values underlying models as ethical frameworks. We employ an experimental, evidence-based approach that challenges the models with ethical dilemmas in order to probe human-AI alignment. The ethical scenarios are designed to require a decision in which the particulars of the situation may or may not necessitate deviating from normative ethical principles. A sophisticated ethical framework was consistently elicited in one model, GPT-4. Nonetheless, troubling findings include underlying normative frameworks with clear bias towards particular cultural norms. Many models also exhibit disturbing authoritarian tendencies. Code is available at https://github.com/jon-chun/llm-sota-chatbots-ethics-based-audit

## KEYWORDS

large language models (LLMs), AI safety, Human-AI alignment, AI regulation, ethics-based auditing (EBA), AI reasoning, agentic AI, autonomous AI



## ACM Classification

I.2.7; K.4.1; I.2.11; I.6.5

I.2.7 Natural Language Processing: As your paper focuses on Large Language Models (LLMs) like GPT-4, which are central to natural language processing, this category is highly relevant. It directly addresses the technological basis of your research.

K.4.1 Public Policy Issues - Ethics: This category is pertinent due to the ethical audit aspect of your paper. It covers the ethical implications and considerations in computing, which are central to your research's focus on assessing moral reasoning and normative values in LLMs.

I.2.11 Distributed Artificial Intelligence - Intelligent agents: Given the emphasis on autonomous agents and their networked collaboration, this category is relevant. It encompasses the study of AI systems that operate in distributed environments, which seems pertinent to your focus on commercial and open-source LLMs.

I.6.5 Model Development: This category is applicable for the aspect of your paper that deals with the development and assessment of AI models, particularly in the context of ethical frameworks and moral reasoning.

## MSC Classification

68T27; 68T30; 68T37; 01A80

68T27 Logic in artificial intelligence: This class covers the use of logic in AI, which could be relevant if your paper involves logical frameworks or reasoning processes within AI models.

68T30 Knowledge representation: If your paper delves into how knowledge is represented within AI models, particularly in the context of ethical reasoning, this class would be applicable.

68T37 Reasoning under uncertainty: This is relevant if your paper discusses how LLMs handle ethical dilemmas or decisions under conditions of uncertainty.

01A80 Sociology (and profession) of mathematics: While not directly related to AI, this class could be relevant if your paper touches on broader ethical or societal implications of AI in decision-making.
